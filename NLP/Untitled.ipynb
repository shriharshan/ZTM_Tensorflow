{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27938849-1e86-4227-8014-1b8880b2466d",
   "metadata": {},
   "source": [
    "# Architecture of an RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05c1495-7f9f-4e32-838b-4d9cfe41331b",
   "metadata": {},
   "source": [
    "| Hyperparameter/Layer type | What does it do?                                                                       | Typical Values                                                                                |\r\n",
    "|---------------------------|----------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------|\r\n",
    "| input texts(s)            | Takes in target sequence                                                               | `input_shape = [batch_size, embedding_size]` or `[batch_size, sequence_shape]`                |\r\n",
    "| Text Vectorization layer  | Maps input sequence to number                                                          | Multiple, can create with `tf.keras.layers.experimental.preprocessing.TextVectorization`      |\r\n",
    "| Embeddings                | Turns mapping of text vectors to embedding matrix (representation of how words relate) | Multiple, can create with `tf.keras.layers.Embedding`                                         |\r\n",
    "| RNN cell(s)               | Finds patterns in sequences                                                            | `SimpleRNN, LSTM, GRU`                                                                        |\r\n",
    "| Hidden activation         | Adds non-linearity to learned features (non-straight lines)                            | Usually Tanh (hyperbolic tangent) (`tf.keras.activation.tanh`)                                |\r\n",
    "| Pooling layer             | Reduces the dimensionality of learned sequence features (usually for Conv1D models)    | Average (`tf.keras.layers.GlobalAveragePooling1D`) or Max (`tf.keras.layers.GlobalMaxPool1D`) |\r\n",
    "| Fully connected layer     | Further refines learned features from recurrent layers                                 | `tf.keras.layers.Dense`                                                                       |\r\n",
    "| Output layer              | Takes learned features and outputs them in shape of target labels                      | `output_shape = [number_of_classes]`                                                          |\r\n",
    "| Output Activation         | Adds non-linearity to output layer                                                     | `tf.keras.activation.sigmoid` (binary classification) or `tf.keras.activation.softmax`        |\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "3e7c9937-5e4a-497b-a756-98c985cf3760",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import create_tensorboard_callback, plot_loss_curves, compare_historys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b571d446-0e9d-4762-af96-b73a6594d98a",
   "metadata": {},
   "source": [
    "## Get a Text Dataset\n",
    "The dataset we'regoing to be using is Kaggle's introduction to NLP dataset (text samples of Tweets labelled as disaster or not disaster)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9c7bea-aaad-4c5d-8c2d-ebf5a9cd9fec",
   "metadata": {},
   "source": [
    "## Visualizing a text dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f4d7714-c70c-4f6a-b12f-a9289e8c10cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('Data/nlp_getting_started/train.csv')\n",
    "test_df = pd.read_csv('Data/nlp_getting_started/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "807b0343-ba9a-45ae-b166-09815f0d6d33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e7fdc1d-3770-48fc-b1c0-052468df5121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2644</th>\n",
       "      <td>3796</td>\n",
       "      <td>destruction</td>\n",
       "      <td>NaN</td>\n",
       "      <td>So you have a new weapon that can cause un-ima...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2227</th>\n",
       "      <td>3185</td>\n",
       "      <td>deluge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5448</th>\n",
       "      <td>7769</td>\n",
       "      <td>police</td>\n",
       "      <td>UK</td>\n",
       "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>191</td>\n",
       "      <td>aftershock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aftershock back to school kick off was great. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6845</th>\n",
       "      <td>9810</td>\n",
       "      <td>trauma</td>\n",
       "      <td>Montgomery County, MD</td>\n",
       "      <td>in response to trauma Children of Addicts deve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id      keyword               location  \\\n",
       "2644  3796  destruction                    NaN   \n",
       "2227  3185       deluge                    NaN   \n",
       "5448  7769       police                     UK   \n",
       "132    191   aftershock                    NaN   \n",
       "6845  9810       trauma  Montgomery County, MD   \n",
       "\n",
       "                                                   text  target  \n",
       "2644  So you have a new weapon that can cause un-ima...       1  \n",
       "2227  The f$&amp;@ing things I do for #GISHWHES Just...       0  \n",
       "5448  DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...       1  \n",
       "132   Aftershock back to school kick off was great. ...       0  \n",
       "6845  in response to trauma Children of Addicts deve...       0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffle training dataframe\n",
    "train_df_shuffled = train_df.sample(frac=1, random_state=42)\n",
    "train_df_shuffled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f02e8d4-5594-42ec-81c3-0e4ff3113e0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash\n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a262d6b-0c86-4b80-ab1f-8d3e89a4df9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    4342\n",
       "1    3271\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many examples of each class?\n",
    "train_df.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "077a99ee-6b52-4f95-a8c0-19f688c69b4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 3263)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many total samples?\n",
    "len(train_df), len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1db280eb-95c4-464c-a15d-3a9416366268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: 1 {real disaster}\n",
      "Text:\n",
      "And please don't flood poor @RobertBEnglund's mentions. He's put in his work!\n",
      "\n",
      "---\n",
      "\n",
      "Target: 1 {real disaster}\n",
      "Text:\n",
      "West Valley I405 N / Us101 S I405 N Con **Trfc Collision-Unkn Inj** http://t.co/jS9EhP88wQ\n",
      "\n",
      "---\n",
      "\n",
      "Target: 0 (not real disaster)\n",
      "Text:\n",
      "@b24fowler I see that! Crazy how this line blew up.\n",
      "\n",
      "---\n",
      "\n",
      "Target: 0 (not real disaster)\n",
      "Text:\n",
      "@daewony0406 alright now I'm gonna crash I'm so exhausted\n",
      "\n",
      "---\n",
      "\n",
      "Target: 1 {real disaster}\n",
      "Text:\n",
      "Investigators say a fatal Virgin Galactic spaceship crash last year was caused by structural failure after the... http://t.co/FPrt7NwrOt\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's visuallize some random training examples\n",
    "import random\n",
    "random_index = random.randint(0, len(train_df)-5)# Create random indexes not higher than the total number of samples \n",
    "for row in train_df_shuffled[['text','target']][random_index: random_index+5].itertuples():\n",
    "    _, text, target = row\n",
    "    print(f\"Target: {target}\", \"{real disaster}\" if target > 0 else \"(not real disaster)\")\n",
    "    print(f\"Text:\\n{text}\\n\")\n",
    "    print(\"---\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af502571-a7ef-4e5a-a128-bc0f24648150",
   "metadata": {},
   "source": [
    "### Split data into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f458664-afe7-4647-bdc7-5b315d2fec99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "673a9260-94d5-4c47-b8d9-edd26f6a996a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use train_test_split to split training data into training and validation sets\n",
    "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_df_shuffled['text'].to_numpy(),\n",
    "                                                                           train_df_shuffled['target'].to_numpy(),\n",
    "                                                                           test_size = 0.1 ,# use 10% of training data for validation split\n",
    "                                                                           random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "431105cf-f680-43a7-8218-1bafa3675865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6851, 6851, 762, 762)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the lengths\n",
    "len(train_sentences), len(train_labels), len(val_sentences), len(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fbf98860-e68c-4aaa-afe8-98151a6d6d96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
       "        'Imagine getting flattened by Kurt Zouma',\n",
       "        '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
       "        \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
       "        'Somehow find you and I collide http://t.co/Ee8RpOahPk',\n",
       "        '@EvaHanderek @MarleyKnysh great times until the bus driver held us hostage in the mall parking lot lmfao',\n",
       "        'destroy the free fandom honestly',\n",
       "        'Weapons stolen from National Guard Armory in New Albany still missing #Gunsense http://t.co/lKNU8902JE',\n",
       "        '@wfaaweather Pete when will the heat wave pass? Is it really going to be mid month? Frisco Boy Scouts have a canoe trip in Okla.',\n",
       "        'Patient-reported outcomes in long-term survivors of metastatic colorectal cancer - British Journal of Surgery http://t.co/5Yl4DC1Tqt'],\n",
       "       dtype=object),\n",
       " array([0, 0, 1, 0, 0, 1, 1, 0, 1, 1], dtype=int64))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the first 10 samples\n",
    "train_sentences[:10], train_labels[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d031999c-e7d9-412f-bb54-154722d6ae47",
   "metadata": {},
   "source": [
    "## Converting text into numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74159852-2a9b-424a-8363-a983bfaad33b",
   "metadata": {},
   "source": [
    "**Tokenization** \n",
    "- A straight mapping from word or character or sub-word to a numerical value. There are three main levels of tokenization:\n",
    "1. Using **word-level tokenization** with the sentence \"I love TensorFlow\" might result in \"I\" being 0, \"love\" being 1 and \"TensorFlow\" being 2. In this case, every word in a sequence considered a single **token**.\n",
    "2. **Character-level tokenization**, such as converting the letters A-Z to values 1-26. In this case, every character in a sequence considered a single **token**.\n",
    "3. **Sub-word tokenization** is in between word-level and character-level tokenization. It involves breaking invidual words into smaller parts and then converting those smaller parts into numbers. For example, \"my favourite food is pineapple pizza\" might become \"my, fav, avour, rite, fo, oo, od, is, pin, ine, app, le, piz, za\". After doing this, these sub-words would then be mapped to a numerical value. In this case, every word could be considered multiple **tokens**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb34cf97-72ba-49d0-bff7-79b2c551fe6f",
   "metadata": {},
   "source": [
    "**Embeddings** \n",
    "- An embedding is a representation of natural language which can be learned. Representation comes in the form of a **feature vector**. For example, the word \"dance\" could be represented by the 5-dimensional vector [-0.8547, 0.4559, -0.3332, 0.9877, 0.1112]. It's important to note here, the size of the feature vector is tuneable. There are two ways to use embeddings:\n",
    "1. **Create your own embedding** - Once your text has been turned into numbers (required for an embedding), you can put them through an embedding layer (such as tf.keras.layers.Embedding) and an embedding representation will be learned during model training.\n",
    "2. **Reuse a pre-learned embedding** - Many pre-trained embeddings exist online. These pre-trained embeddings have often been learned on large corpuses of text (such as all of Wikipedia) and thus have a good underlying representation of natural language. You can use a pre-trained embedding to initialize your model and fine-tune it to your own specific task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb7fa02-1906-406f-b7b8-39e483acb5d9",
   "metadata": {},
   "source": [
    "### Text Vectorization (tokenization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "598c894d-610e-4e67-a68a-f36c457de982",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2d04a61-cb9f-460e-9f46-819d666d7eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\shrih\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_vectorizer = TextVectorization(max_tokens=None, # how many words in the vocabulary\n",
    "                                   standardize=\"lower_and_strip_punctuation\",\n",
    "                                   split=\"whitespace\",\n",
    "                                   ngrams=None, # Create groups of n-words\n",
    "                                   output_mode='int', # how to map tokens to numbers\n",
    "                                   output_sequence_length=None, # how long do you want your sequence to be?\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b69e755-b22b-46df-ac38-ec4c58a8f38d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_sentences[0].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe8f7c4b-e265-4bf2-b52c-8f7a0c54c84d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102087"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(sum([len(i.split()) for i in train_sentences]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f548fd5-5152-49dd-90d7-45c378b42680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the average number of tokens (words) in the training tweets\n",
    "round(sum([len(i.split()) for i in train_sentences]) / len(train_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7b39555-7461-48a1-8f7c-0f06df522311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup text vectorization variables\n",
    "max_vocab_length = 10000 # max number of words to have in our vocabulary\n",
    "max_length = 15 # max length our sequence will be (e.g. how many words from a Tweet does a model see?)\n",
    "\n",
    "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
    "                                      output_sequence_length=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "deae4edb-a0da-4d6f-9c4e-bca01269492e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\shrih\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fit the text vecotrizer to the training text\n",
    "text_vectorizer.adapt(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b1e21aed-61ac-4649-ae7d-26600031bfda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
       "array([[264,   3, 232,   4,  13, 698,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=int64)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a sample sentence and tokenize it\n",
    "sample_sentence = \"There's a flood in my street!\"\n",
    "text_vectorizer([sample_sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a8b41c35-828f-492d-be04-a58c68ff5634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      " mentions of 'theatre +shooting' on Twitter spike 30min prior to $ckec collapse http://t.co/uuBOvy9GQI     \n",
      "\n",
      "Vectorized version: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
       "array([[2050,    6, 1951,  617,   11,  382, 8223,    1, 2782,    5,    1,\n",
       "         155,    1,    0,    0]], dtype=int64)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose a random sentence from the training dataset and tokenize it\n",
    "random_sentence = random.choice(train_sentences)\n",
    "print(f\"Original text:\\n {random_sentence}\\\n",
    "     \\n\\nVectorized version: \")\n",
    "text_vectorizer([random_sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c36cfd22-a0ad-43d8-9b76-4d36073e7907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in vocab: 10000\n",
      "5 Most common words: ['', '[UNK]', 'the', 'a', 'in']\n",
      "5 Least common words: ['pages', 'paeds', 'pads', 'padres', 'paddytomlinson1']\n"
     ]
    }
   ],
   "source": [
    "# Get the unique words in vocabulary\n",
    "words_in_vocab = text_vectorizer.get_vocabulary() # get all of the unique words in the training data\n",
    "top_5_words = words_in_vocab[:5] # get the most common words\n",
    "bottom_5_words = words_in_vocab[-5:] # get the least common words\n",
    "print(f\"Number of words in vocab: {len(words_in_vocab)}\")\n",
    "print(f\"5 Most common words: {top_5_words}\")\n",
    "print(f\"5 Least common words: {bottom_5_words}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c737035-9e9f-4195-b264-5216f99db744",
   "metadata": {},
   "source": [
    "### Creating an Embedding using Embeddin Layer\n",
    "\n",
    "The paramter we care most about for our embedding layer:\n",
    "- `input_dim` = the size of our vocabulary\n",
    "- `output_dim` = the size of the output embedding vector, for example, a value of 100 would mean each token gets represented by a vector 100 long\n",
    "- `input_length` = length of the sequences being passed to the embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2dd178dd-18c7-45cc-bac2-33c3b7a68bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "66969503-b752-45c7-831b-f40c6eb99da3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 15)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_vocab_length, max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ec9d839b-1e46-43a2-847d-805cba6791f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.layers.core.embedding.Embedding at 0x108d9a79b40>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = layers.Embedding(input_dim=max_vocab_length, # set input shape\n",
    "                            output_dim=128, # output shape\n",
    "                            input_length=max_length # how long is each input\n",
    "                            ) \n",
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "83a1842d-af6d-4f53-8667-ea86c90651ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      " Harshness Follows Us a\n",
      "Better Day\n",
      "by Sarah C\n",
      "Racing thoughts with screaming sirens\n",
      "Pacing back and forth for... http://t.co/ProNtOuo91    \n",
      "Embedded version:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
       "array([[[-0.03090152, -0.03370758,  0.00092022, ..., -0.00383916,\n",
       "          0.01627164, -0.01622596],\n",
       "        [ 0.04146374,  0.0239217 ,  0.04596612, ..., -0.03964501,\n",
       "          0.02929964, -0.00799692],\n",
       "        [-0.02877517,  0.02431269, -0.00027614, ...,  0.04852494,\n",
       "         -0.01090112,  0.0163198 ],\n",
       "        ...,\n",
       "        [ 0.00623779,  0.03105433, -0.01683553, ...,  0.04877551,\n",
       "         -0.02308056, -0.04875856],\n",
       "        [-0.03341652, -0.04855214, -0.0485457 , ..., -0.0147303 ,\n",
       "          0.0390857 ,  0.02931849],\n",
       "        [-0.03090152, -0.03370758,  0.00092022, ..., -0.00383916,\n",
       "          0.01627164, -0.01622596]]], dtype=float32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a random sentence from the training set\n",
    "random_sentence = random.choice(train_sentences)\n",
    "print(f\"Original text:\\n {random_sentence}\\\n",
    "    \\nEmbedded version:\")\n",
    "\n",
    "# Embed the random sentence (turn it into dense vectors of fixed size)\n",
    "sample_embed = embedding(text_vectorizer([random_sentence]))\n",
    "sample_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2425bb16-0de9-403b-920d-898e3bbbe5a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
       " array([-0.03090152, -0.03370758,  0.00092022, -0.0086095 , -0.03804547,\n",
       "        -0.04493318,  0.02411605,  0.03888411, -0.0249571 , -0.0306203 ,\n",
       "         0.03890071,  0.0379152 , -0.0357147 , -0.03568275,  0.00411243,\n",
       "         0.04556698,  0.02997614, -0.03850775, -0.00965884, -0.03599235,\n",
       "        -0.01208848,  0.03207758,  0.01139784, -0.02447828, -0.04857664,\n",
       "         0.01688609, -0.02861773, -0.0019627 ,  0.04603562, -0.00577309,\n",
       "         0.04666367, -0.02760726, -0.01030301, -0.01411235, -0.02219879,\n",
       "         0.0304342 , -0.04332565,  0.01761342, -0.03292984, -0.03531207,\n",
       "         0.00359563, -0.03467093,  0.00055759,  0.03771878, -0.01229365,\n",
       "        -0.01313975, -0.02315599,  0.01225804, -0.01941505, -0.03976064,\n",
       "        -0.00790075,  0.00418667,  0.00695854, -0.00357392,  0.03846038,\n",
       "         0.00647309, -0.03798984,  0.03680476,  0.01285467, -0.03841024,\n",
       "        -0.02369889,  0.00769509,  0.02900166,  0.02894132,  0.01656932,\n",
       "         0.02128172,  0.04478966,  0.02107162, -0.00959828, -0.01547012,\n",
       "         0.00524825,  0.03452598, -0.00610089,  0.02696632,  0.00380205,\n",
       "        -0.03973689,  0.00405155, -0.00394983, -0.00841501, -0.04470487,\n",
       "         0.00510639,  0.00634629,  0.01438424, -0.01964146, -0.01967303,\n",
       "        -0.03246728, -0.04907646,  0.0214971 , -0.0419229 ,  0.04408224,\n",
       "        -0.03043598, -0.03426196,  0.0389809 , -0.04890258,  0.04431092,\n",
       "         0.04888269, -0.0169212 , -0.03977967, -0.04102153, -0.04618806,\n",
       "        -0.03603814,  0.01692666, -0.02046865, -0.01534792,  0.00220621,\n",
       "         0.01463535,  0.02016293,  0.0290591 , -0.04779239, -0.02240591,\n",
       "         0.03266494,  0.04792323,  0.0146294 , -0.00172863, -0.01020437,\n",
       "        -0.04996816,  0.0457366 , -0.01691943,  0.03596324,  0.03513094,\n",
       "        -0.01742817, -0.0468575 , -0.01209833, -0.02710197, -0.0134712 ,\n",
       "        -0.00383916,  0.01627164, -0.01622596], dtype=float32)>,\n",
       " TensorShape([128]),\n",
       " 'Harshness Follows Us a\\nBetter Day\\nby Sarah C\\nRacing thoughts with screaming sirens\\nPacing back and forth for... http://t.co/ProNtOuo91')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out a single token's embedding\n",
    "sample_embed[0][0], sample_embed[0][0].shape, random_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba9b771-2924-4b3c-bd1a-20279b30e60b",
   "metadata": {},
   "source": [
    "## Modelling a text dataset (running a series of experiments)\n",
    "\n",
    "We'll start with a baseline and move on from there.\n",
    "\n",
    "* Model 0: Naive Bayes (baseline)\n",
    "* Model 1: Feed-Forword neural network (dense model)\n",
    "* Model 2: LSTM model (RNN)\n",
    "* Model 3: GRU model (RNN)\n",
    "* Model 4: Bidirectional-LSTM model (RNN)\n",
    "* Model 5: 1D Convulational Neural Network (CNN)\n",
    "* Model 6: TensorFlow Hub Pretrained Feature Extractor (using tranfer learning for NLP)\n",
    "* Model 7: Same as model 6 with 10% of training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3dba7b-7fab-412a-8cfa-9ae8be9e043a",
   "metadata": {},
   "source": [
    "## Model 0: Baseline\n",
    "\n",
    "To create our baseline, we'll use Sklearn's Multinomial Naive Bayes using TF-IDF formula to convert our words to numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c9942535-f924-403d-8a45-91e8e2a2918f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0a80124a-4023-42c1-9b67-6e14745d5cd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create tokenization and modelling pipeline\n",
    "model_0 = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer()), # Converts words to numbers using tfidf\n",
    "    (\"clf\", MultinomialNB()) # Model the text\n",
    "])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "model_0.fit(train_sentences, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9ffcddb6-5d31-4d5c-8324-cb717fa0bd33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our baseline model achieves an accuracy of: 79.27%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate our baseline model\n",
    "baseline_score = model_0.score(val_sentences, val_labels)\n",
    "print(f\"Our baseline model achieves an accuracy of: {baseline_score*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a6bc755f-bbf6-4bd8-a832-bcabbdcc4ff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions\n",
    "baseline_preds = model_0.predict(val_sentences)\n",
    "baseline_preds[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051e3e10-5a7f-4db8-91e4-3d0aa4d58ac8",
   "metadata": {},
   "source": [
    "### Creating an evluation function for our model experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "249c6893-8b44-4ad7-ac0e-e5dc96654752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to evaluate: accuracy, precision, recall, f1-score\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def calculate_results(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates model accuracy, precision, recall and f1 score of a binary classification model.\n",
    "    \"\"\"\n",
    "    # Calculate model accuracy\n",
    "    model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
    "    # Calculate model precision, recall and f1-score using \"weighted\" average\n",
    "    model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
    "    model_results = {\"accuracy\": model_accuracy,\n",
    "                    \"precision\": model_precision,\n",
    "                    \"recall\": model_recall,\n",
    "                    \"f1-score\": model_f1}\n",
    "    return model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cb57831b-ab9c-419c-acd6-2d0c643ada2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 79.26509186351706,\n",
       " 'precision': 0.8111390004213173,\n",
       " 'recall': 0.7926509186351706,\n",
       " 'f1-score': 0.7862189758049549}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get baseline results\n",
    "baseline_results = calculate_results(y_true=val_labels,\n",
    "                                    y_pred=baseline_preds)\n",
    "baseline_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e8d59a-0493-42d4-9d31-712ed86cf029",
   "metadata": {},
   "source": [
    "## Model 1: A simple dense model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5e756667-38a1-4d10-a037-cbed4bdb81ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tensorboard vallback (need to create a new one for each model)\n",
    "\n",
    "# Create a directory to save Tensorboard logs\n",
    "SAVE_DIR = \"model_logs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "835154a9-350a-4d17-9f05-5d05c0934659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buils model with the Functional API\n",
    "inputs = layers.Input(shape=(1,), dtype=tf.string) #inputs are 1-dimensional strings\n",
    "x = text_vectorizer(inputs) # Turn the input texts into numbers\n",
    "x = embedding(x) # create an embedding of the numberized inputs\n",
    "# x = layers.GlobalAveragePooling1D()(x) # condense the feature vector for each token to one vector\n",
    "x = layers.GlobalMaxPool1D()(x)\n",
    "outputs = layers.Dense(1, activation='sigmoid')(x) # create the output layer, want binary outputs so use sigmoid activation function\n",
    "model_1 = tf.keras.Model(inputs, outputs, name=\"model_1_dense\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dc0e4e5a-eb2c-4f04-b838-f74319f8a3c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1_dense\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (Text  (None, 15)                0         \n",
      " Vectorization)                                                  \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " global_max_pooling1d (Glob  (None, 128)               0         \n",
      " alMaxPooling1D)                                                 \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1280129 (4.88 MB)\n",
      "Trainable params: 1280129 (4.88 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f3a9ffa9-af9b-4418-8f3b-fed27f018cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model_1.compile(loss=\"binary_crossentropy\",\n",
    "               optimizer=tf.keras.optimizers.Adam(),\n",
    "               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1235e615-7bf3-4197-97ff-8b4eb38ccb76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_1_dense/20240110-213727\n",
      "Epoch 1/5\n",
      "WARNING:tensorflow:From C:\\Users\\shrih\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "215/215 [==============================] - 6s 15ms/step - loss: 0.6389 - accuracy: 0.6633 - val_loss: 0.5715 - val_accuracy: 0.7769\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 3s 14ms/step - loss: 0.4671 - accuracy: 0.8314 - val_loss: 0.4663 - val_accuracy: 0.7848\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 0.3397 - accuracy: 0.8740 - val_loss: 0.4461 - val_accuracy: 0.7992\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 0.2572 - accuracy: 0.9070 - val_loss: 0.4518 - val_accuracy: 0.7979\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 0.1975 - accuracy: 0.9343 - val_loss: 0.4640 - val_accuracy: 0.7887\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model_1_history = model_1.fit(train_sentences,\n",
    "                              train_labels,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_sentences, val_labels),\n",
    "                              callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
    "                                                                    experiment_name='model_1_dense')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "611d51a3-a503-4033-a387-1231474b35e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.7887\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.46402522921562195, 0.7887139320373535]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the results\n",
    "model_1.evaluate(val_sentences, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8179ba40-4ffd-414b-bb55-5b154ea7eacb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.41438612], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make some predictions and evaluate those\n",
    "model_1_pred_probs = model_1.predict(val_sentences)\n",
    "model_1_pred_probs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1e8b9909-c4cf-447a-a746-cd0bdede8e41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert model prediction probabilites to label format\n",
    "model_1_preds = tf.squeeze(tf.round(model_1_pred_probs))\n",
    "model_1_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5b51f1e3-96a7-4dd8-bf98-b254d08c12e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 78.87139107611549,\n",
       " 'precision': 0.7943691525527891,\n",
       " 'recall': 0.7887139107611548,\n",
       " 'f1-score': 0.7855210885289512}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate our model_1 results\n",
    "model_1_results = calculate_results(y_true=val_labels,\n",
    "                                   y_pred=model_1_preds)\n",
    "model_1_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed074ada-6b21-451f-8c91-33b7d6928b4d",
   "metadata": {},
   "source": [
    "## Visualizing learned embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2dd861eb-4449-4ced-9208-30830bdacd67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, ['', '[UNK]', 'the', 'a', 'in', 'to', 'of', 'and', 'i', 'is'])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the vocabulary from the text vectorization layer\n",
    "words_in_vocab = text_vectorizer.get_vocabulary()\n",
    "len(words_in_vocab), words_in_vocab[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "11da540c-d231-4854-a588-734cfcb5a51b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1_dense\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (Text  (None, 15)                0         \n",
      " Vectorization)                                                  \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " global_max_pooling1d (Glob  (None, 128)               0         \n",
      " alMaxPooling1D)                                                 \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1280129 (4.88 MB)\n",
      "Trainable params: 1280129 (4.88 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model 1 summary\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8bafa5ff-6a67-4d7d-af1d-229b332ed118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 128)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the weight matrix of embedding layer\n",
    "# these are the numerical representations of each token in our training data, which have been learned for -5 epochs\n",
    "embed_weights = model_1.get_layer(\"embedding\").get_weights()[0]\n",
    "embed_weights.shape # same size as vocab size and embedding_dim (output_dim of our embedding layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a4d31302-4490-442e-8dec-2ca275f618ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embedding files (we got this from TensorFlow's word embeddings documentation)\n",
    "import io\n",
    "out_v = io.open('vectors.tsv', 'w', encoding='utf-8')\n",
    "out_m = io.open('metadata.tsv', 'w', encoding='utf-8')\n",
    "\n",
    "for index, word in enumerate(words_in_vocab):\n",
    "  if index == 0:\n",
    "    continue  # skip 0, it's padding.\n",
    "  vec = embed_weights[index]\n",
    "  out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
    "  out_m.write(word + \"\\n\")\n",
    "out_v.close()\n",
    "out_m.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228e59d8-fddb-470b-aa15-2b8d8f5f63c8",
   "metadata": {},
   "source": [
    "## Recurrent Neural Networks (RNN's)\n",
    "\n",
    "RNN's are useful for sequence data.\n",
    "\n",
    "The output from the previous step is fed as input to the current step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605eb12b-4727-4174-9f98-c6c5014c12f3",
   "metadata": {},
   "source": [
    "## Model 2: LSTM\n",
    "\n",
    "LSTM = Long Short Term Memory\n",
    "\n",
    "Our structure of an RNN typically looks like this:\n",
    "\n",
    "`input (text) -> Tokenize -> Embedding -> Layers (RNNs/dense) -> Output (labbel probability)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3a9c01-ed08-43a9-9c74-d15dc9a78dc4",
   "metadata": {},
   "source": [
    "### LSTM: Key concepts\n",
    "\n",
    "1. Maintain a **cell state**\n",
    "2. USe **gates** to control the flow of information\n",
    "   * **Forget** gate gets rid of irrelevant information\n",
    "   * **Store** relevent information from current input\n",
    "   * Selectively **update** cell state\n",
    "   * **Output** gate returns a filtered version of the cell state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b521a3-ba47-4e2e-90be-825a615fc8d8",
   "metadata": {},
   "source": [
    "And to make sure we're not getting reusing trained embeddings (this would involve data leakage between models, leading to an uneven comparison later on), we'll create another embedding layer `(model_2_embedding)` for our model.The `text_vextorizer` layer can vev reused since it doesn't get updated during training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e4f2cc-724b-4871-a07c-c40966ce8a2b",
   "metadata": {},
   "source": [
    "> 🔑 **NOTE**: The reason we use a new embedding layer for each model is since the embedding layer is a learned representation of words (as numbers), if we were to use the same embedding layer `(embedding_1)` for each model, we'd be mixing what one model learned with the next. And because we want to compare our models later on, starting them with their own embedding layer each time is a better idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "190947b3-66e6-471b-8d90-3f8038d0f484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 15, 128)\n",
      "(None, 64)\n"
     ]
    }
   ],
   "source": [
    "# Set random seed and create embedding layer (new embedding layer for each model)\n",
    "tf.random.set_seed(42)\n",
    "model_2_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
    "                                    output_dim=128,\n",
    "                                    embeddings_initializer='uniform',\n",
    "                                    input_length=max_length,\n",
    "                                    name=\"embedding_2\")\n",
    "\n",
    "# Create an LSTM model\n",
    "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = model_2_embedding(x)\n",
    "print(x.shape)\n",
    "# x = layers.LSTM(64, return_sequences=True) # When you're stacking RNN cells together, you need to set return_sequence=True\n",
    "x = layers.LSTM(64)(x)\n",
    "print(x.shape)\n",
    "# x = layers.Dense(64, activation='relu')(x)\n",
    "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "model_2 = tf.keras.Model(inputs, outputs, name=\"model_2_LSTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5283f6a2-b961-490c-8e95-e306449480de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2_LSTM\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (Text  (None, 15)                0         \n",
      " Vectorization)                                                  \n",
      "                                                                 \n",
      " embedding_2 (Embedding)     (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                49408     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1329473 (5.07 MB)\n",
      "Trainable params: 1329473 (5.07 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Get a summary\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6d809859-f8b8-4687-9837-bc4131c9ac53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model_2.compile(loss='binary_crossentropy',\n",
    "               optimizer=tf.keras.optimizers.Adam(),\n",
    "               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f91ee71b-ecaf-4bf9-b52e-8a35db005cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_2_LSTM/20240110-213746\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 7s 22ms/step - loss: 0.5079 - accuracy: 0.7454 - val_loss: 0.4557 - val_accuracy: 0.7730\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 4s 19ms/step - loss: 0.3145 - accuracy: 0.8727 - val_loss: 0.5182 - val_accuracy: 0.7730\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 4s 20ms/step - loss: 0.2170 - accuracy: 0.9168 - val_loss: 0.5864 - val_accuracy: 0.7625\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 4s 19ms/step - loss: 0.1519 - accuracy: 0.9476 - val_loss: 0.5895 - val_accuracy: 0.7782\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 4s 19ms/step - loss: 0.1051 - accuracy: 0.9616 - val_loss: 0.8520 - val_accuracy: 0.7612\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model_2_history = model_2.fit(train_sentences,\n",
    "                             train_labels,\n",
    "                             epochs=5,\n",
    "                             validation_data=(val_sentences,val_labels),\n",
    "                             callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
    "                                                                   \"model_2_LSTM\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0ae5a010-77c3-46b1-8909-91c2d362075e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00364079],\n",
       "       [0.71935016],\n",
       "       [0.9991115 ],\n",
       "       [0.06534643],\n",
       "       [0.00171622],\n",
       "       [0.9993588 ],\n",
       "       [0.70030916],\n",
       "       [0.99959844],\n",
       "       [0.9993064 ],\n",
       "       [0.24501963]], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions with LSTM model\n",
    "model_2_pred_probs = model_2.predict(val_sentences)\n",
    "model_2_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e8f2f510-a48c-4827-be80-f10e648c2ee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert model_2 pred probs to labels\n",
    "model_2_preds = tf.squeeze(tf.round(model_2_pred_probs))\n",
    "model_2_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a1ac220e-e8a5-462a-b822-38e200b1c670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 76.11548556430446,\n",
       " 'precision': 0.7627664723727715,\n",
       " 'recall': 0.7611548556430446,\n",
       " 'f1-score': 0.7588524417705016}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate model_2 results\n",
    "model_2_results = calculate_results(y_true=val_labels,\n",
    "                                   y_pred=model_2_preds)\n",
    "model_2_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8787ce0c-ca05-44ba-aaac-183543a1ad03",
   "metadata": {},
   "source": [
    "## Model 3: GRU\n",
    "\n",
    "The GRU cell has similar features to an LSTM cell but has less paramters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a801c197-3d6e-4b47-a8b8-a69eb9bcb294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed and create embedding layer (new embedding layer for each model)\n",
    "tf.random.set_seed(42)\n",
    "model_3_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
    "                                    output_dim=128,\n",
    "                                    input_length=max_length,\n",
    "                                    name=\"embedding_3\")\n",
    "\n",
    "# Build an RNN using GRU cell\n",
    "inputs = tf.keras.Input(shape=(1,), dtype=\"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = model_3_embedding(x)\n",
    "x = layers.GRU(64)(x)\n",
    "# x = layers.GRU(64, return_sequences=True)(x) # if we want to stack recurrent layers on top of each other, you need to set return_sequence=True\n",
    "# print(x.shape)\n",
    "# x = layers.LSTM(64, return_sequences=True)(x)\n",
    "# print(x.shape)\n",
    "# x = layers.GRU(64)(x)\n",
    "# print(x.shape)\n",
    "# x = layers.Dense(64, activation='relu')(x)\n",
    "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "model_3 = tf.keras.Model(inputs, outputs, name=\"model_3_GRU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8c0d56c5-a0f2-4d29-9d02-2482111df623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3_GRU\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (Text  (None, 15)                0         \n",
      " Vectorization)                                                  \n",
      "                                                                 \n",
      " embedding_3 (Embedding)     (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 64)                37248     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1317313 (5.03 MB)\n",
      "Trainable params: 1317313 (5.03 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fdb9d4d2-8a5c-486d-a049-8e7a580ab776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model_3.compile(loss='binary_crossentropy',\n",
    "               optimizer=tf.keras.optimizers.Adam(),\n",
    "               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "19dd0484-bd1d-433d-9c57-ef845640f843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_3_GRU/20240110-213810\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 7s 23ms/step - loss: 0.5308 - accuracy: 0.7228 - val_loss: 0.4558 - val_accuracy: 0.7756\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 4s 20ms/step - loss: 0.3198 - accuracy: 0.8672 - val_loss: 0.4908 - val_accuracy: 0.7835\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 4s 20ms/step - loss: 0.2151 - accuracy: 0.9178 - val_loss: 0.5698 - val_accuracy: 0.7743\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 4s 20ms/step - loss: 0.1500 - accuracy: 0.9491 - val_loss: 0.6460 - val_accuracy: 0.7756\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 4s 20ms/step - loss: 0.1128 - accuracy: 0.9610 - val_loss: 0.6163 - val_accuracy: 0.7690\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model_3_history = model_3.fit(train_sentences,\n",
    "                             train_labels,\n",
    "                             validation_data=(val_sentences, val_labels),\n",
    "                             epochs=5,\n",
    "                             callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
    "                                                                   \"model_3_GRU\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "022c21fa-29bc-4096-adbe-58d97aeb2615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.40496296],\n",
       "       [0.91693306],\n",
       "       [0.99756384],\n",
       "       [0.1786995 ],\n",
       "       [0.00913915],\n",
       "       [0.99170476],\n",
       "       [0.7482027 ],\n",
       "       [0.99735737],\n",
       "       [0.99536693],\n",
       "       [0.34713897]], dtype=float32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions\n",
    "model_3_pred_probs = model_3.predict(val_sentences)\n",
    "model_3_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "059e8b7e-1a08-4103-9c27-744581c1aaf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert model_3 pred probs to labels\n",
    "model_3_preds = tf.squeeze(tf.round(model_3_pred_probs))\n",
    "model_3_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "959f6650-2a38-45c7-a628-d171533edc2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 76.9028871391076,\n",
       " 'precision': 0.7687652149942675,\n",
       " 'recall': 0.7690288713910761,\n",
       " 'f1-score': 0.7682483510472345}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate model_3 results\n",
    "model_3_results = calculate_results(y_true=val_labels,\n",
    "                                   y_pred=model_3_preds)\n",
    "model_3_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e6ba8f-a693-456c-8318-42cc2f457309",
   "metadata": {},
   "source": [
    "## Model 4: Birdirectional RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1d51b2a6-baed-46f0-b14b-8795e480d943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed and create embedding layer (new embedding layer for each model)\n",
    "tf.random.set_seed(42)\n",
    "model_4_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
    "                                    input_length=max_length,\n",
    "                                    output_dim=128,\n",
    "                                    name=\"embedding_4\",\n",
    "                                    embeddings_initializer=\"uniform\")\n",
    "\n",
    "# build a Birdirectional RNN in TensorFlow\n",
    "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = model_4_embedding(x)\n",
    "# x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x)\n",
    "x = layers.Bidirectional(layers.LSTM(64))(x)\n",
    "outputs =  layers.Dense(1, activation='sigmoid')(x)\n",
    "model_4 = tf.keras.Model(inputs, outputs, name=\"model_4_bidirectional\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4b8dce27-ae46-4300-b52a-2e3473c6bc0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4_bidirectional\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (Text  (None, 15)                0         \n",
      " Vectorization)                                                  \n",
      "                                                                 \n",
      " embedding_4 (Embedding)     (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirecti  (None, 128)               98816     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1378945 (5.26 MB)\n",
      "Trainable params: 1378945 (5.26 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "725e025a-a764-4ad3-ae8e-927bd0b934d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model_4.compile(loss='binary_crossentropy',\n",
    "               optimizer=tf.keras.optimizers.Adam(),\n",
    "               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cface2cf-33d4-4974-9c14-ecdce8f31381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_4_bidirectional/20240110-231443\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 14s 32ms/step - loss: 0.5062 - accuracy: 0.7485 - val_loss: 0.4594 - val_accuracy: 0.7835\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 5s 24ms/step - loss: 0.3113 - accuracy: 0.8753 - val_loss: 0.5389 - val_accuracy: 0.7690\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 5s 25ms/step - loss: 0.2092 - accuracy: 0.9215 - val_loss: 0.5745 - val_accuracy: 0.7664\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 5s 25ms/step - loss: 0.1413 - accuracy: 0.9529 - val_loss: 0.6528 - val_accuracy: 0.7769\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 6s 26ms/step - loss: 0.0987 - accuracy: 0.9653 - val_loss: 0.6831 - val_accuracy: 0.7703\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model_4_history = model_4.fit(train_sentences,\n",
    "                             train_labels,\n",
    "                             validation_data=(val_sentences, val_labels),\n",
    "                             epochs=5,\n",
    "                             callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
    "                                                                   \"model_4_bidirectional\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a986a734-bbb7-4ec3-95d4-1d000255dd99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 2s 8ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.01921569],\n",
       "       [0.81667835],\n",
       "       [0.99922067],\n",
       "       [0.08623891],\n",
       "       [0.00286197],\n",
       "       [0.995832  ],\n",
       "       [0.8114718 ],\n",
       "       [0.9996013 ],\n",
       "       [0.999385  ],\n",
       "       [0.19528708]], dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions\n",
    "model_4_preds_probs = model_4.predict(val_sentences)\n",
    "model_4_preds_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e091603d-065c-483a-be9f-17398f3b4803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4_preds = tf.squeeze(tf.round(model_4_preds_probs))\n",
    "model_4_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "296afe8d-e7fc-4f61-9bc3-88d3cf90088a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 77.03412073490814,\n",
       " 'precision': 0.7726339681635592,\n",
       " 'recall': 0.7703412073490814,\n",
       " 'f1-score': 0.7679241301282296}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the results of our bidirectional model\n",
    "model_4_results = calculate_results(y_true=val_labels,\n",
    "                                   y_pred=model_4_preds)\n",
    "model_4_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b7ee80-75b0-4b92-9af8-dde14ab984ca",
   "metadata": {},
   "source": [
    "## Convolution Neural Network for Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef92f422-7f6b-418a-8ceb-e5e1b2e64fa1",
   "metadata": {},
   "source": [
    "### Model 5: Conv1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f687c89e-b9be-48c0-b163-a82e9365fcc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([1, 15, 128]), TensorShape([1, 15, 32]), TensorShape([1, 32]))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test out our embedding layer, Conv1D layer and max pooling\n",
    "embedding_test = embedding(text_vectorizer(['this is a test sequence'])) # turn target sequence into embedding\n",
    "conv_1d = layers.Conv1D(filters=32,\n",
    "                       kernel_size=5, # this is also referd to as an input ngram of 5 (meaning it looks at 5 words at a time)\n",
    "                       activation='relu',\n",
    "                       padding='same') # default = \"valid\", the output is smaller than the input shape, \"same\" means output is same shape as input\n",
    "\n",
    "conv_1d_output = conv_1d(embedding_test) # pass test embedding through conv1d layer\n",
    "max_pool = layers.GlobalMaxPool1D()\n",
    "max_pool_output = max_pool(conv_1d_output) # equivalent to \"get the most important feature\" or \"get the feature with the highest value\"\n",
    "\n",
    "embedding_test.shape, conv_1d_output.shape, max_pool_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a2ea77f6-5774-4742-bf41-8fdab2d2213e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c34621ae-1689-4aec-8a07-e56fe9cd8def",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# conv_1d_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1929c9e2-9ec5-4abd-ae47-705b174322fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_pool_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d6d89c5e-beb7-40fd-b6da-bafda0d8e1de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5_Conv1D\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (Text  (None, 15)                0         \n",
      " Vectorization)                                                  \n",
      "                                                                 \n",
      " embedding_5 (Embedding)     (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 11, 64)            41024     \n",
      "                                                                 \n",
      " global_max_pooling1d_4 (Gl  (None, 64)                0         \n",
      " obalMaxPooling1D)                                               \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1321089 (5.04 MB)\n",
      "Trainable params: 1321089 (5.04 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Set random seed and create embedding layer (new embedding layer for each model)\n",
    "tf.random.set_seed(42)\n",
    "model_5_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
    "                                    input_length=max_length,\n",
    "                                    output_dim=128,\n",
    "                                    name=\"embedding_5\")\n",
    "\n",
    "# Create 1-dimensional convolutional layer to model sequence\n",
    "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = model_5_embedding(x)\n",
    "x = layers.Conv1D(filters=64, kernel_size=5, activation='relu')(x)\n",
    "x = layers.GlobalMaxPool1D()(x)\n",
    "# x = layers.Dense(64, activation=\"relu\")(x)\n",
    "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "model_5 = tf.keras.Model(inputs, outputs, name=\"model_5_Conv1D\")\n",
    "\n",
    "# Compile the model\n",
    "model_5.compile(loss=\"binary_crossentropy\",\n",
    "               optimizer=tf.keras.optimizers.Adam(),\n",
    "               metrics=['accuracy'])\n",
    "\n",
    "model_5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "de947e29-c3a6-4e2a-911d-3d0956284faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/Conv1D/20240111-212144\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 6s 19ms/step - loss: 0.5454 - accuracy: 0.7289 - val_loss: 0.4605 - val_accuracy: 0.7940\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 4s 17ms/step - loss: 0.3279 - accuracy: 0.8666 - val_loss: 0.4780 - val_accuracy: 0.7913\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 3s 16ms/step - loss: 0.2035 - accuracy: 0.9248 - val_loss: 0.5491 - val_accuracy: 0.7717\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 3s 16ms/step - loss: 0.1285 - accuracy: 0.9577 - val_loss: 0.6270 - val_accuracy: 0.7782\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 4s 18ms/step - loss: 0.0914 - accuracy: 0.9691 - val_loss: 0.6827 - val_accuracy: 0.7887\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model_5_history = model_5.fit(train_sentences,\n",
    "                             train_labels,\n",
    "                             validation_data=(val_sentences, val_labels),\n",
    "                             epochs=5,\n",
    "                             callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
    "                                                                   \"Conv1D\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "32a9b70d-4142-45f3-80ef-efab3c54af45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.57653046],\n",
       "       [0.84108776],\n",
       "       [0.9999529 ],\n",
       "       [0.0578444 ],\n",
       "       [0.0075365 ],\n",
       "       [0.9952683 ],\n",
       "       [0.9701794 ],\n",
       "       [0.9973623 ],\n",
       "       [0.9997266 ],\n",
       "       [0.08895043]], dtype=float32)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5_preds_probs = model_5.predict(val_sentences)\n",
    "model_5_preds_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0b7cb3d2-aa81-428f-8ebe-7ee20c9c2c36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([1., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert model 5 pred probs to labels\n",
    "model_5_preds = tf.squeeze(tf.round(model_5_preds_probs))\n",
    "model_5_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4d656836-b2aa-4894-93a7-dfbf41c76d4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 78.87139107611549,\n",
       " 'precision': 0.7939119079827037,\n",
       " 'recall': 0.7887139107611548,\n",
       " 'f1-score': 0.7856693843184869}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate model 5 results\n",
    "model_5_results = calculate_results(y_true=val_labels,\n",
    "                                   y_pred=model_5_preds)\n",
    "model_5_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbda077-d6e7-4c6b-81b8-56ecfee73e73",
   "metadata": {},
   "source": [
    ">🔑 **Note:** An **Encoder** is the name for a model which converts raw data such as text into numerical representation (feature vector), a **decoder** converts the numerical representation to a desired output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a87948b-e34c-4a76-b8f8-f3942631e897",
   "metadata": {},
   "source": [
    "## model 6: TensorFlow Hub Pretrained Sentence Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "90b8d254-e259-43d8-b12a-825e9c06ec01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\shrih\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow_hub\\module_v2.py:120: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\shrih\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow_hub\\module_v2.py:120: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[-0.01157025  0.02485911  0.02878051 -0.012715    0.03971541  0.08827761\n",
      "  0.02680988  0.05589838 -0.01068731 -0.00597293  0.00639321 -0.01819516\n",
      "  0.00030816  0.09105889  0.05874645 -0.03180629  0.01512474 -0.05162925\n",
      "  0.00991366 -0.06865345 -0.04209306  0.0267898   0.03011009  0.00321065\n",
      " -0.00337968 -0.04787356  0.0226672  -0.00985927 -0.04063615 -0.01292093\n",
      " -0.04666382  0.05630299 -0.03949255  0.00517682  0.02495827 -0.07014439\n",
      "  0.0287151   0.0494768  -0.00633978 -0.08960193  0.02807119 -0.00808364\n",
      " -0.01360601  0.05998649 -0.10361788 -0.05195372  0.00232958 -0.02332531\n",
      " -0.03758106  0.03327729], shape=(50,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_hub as hub\n",
    "embed = hub.load(\"https://www.kaggle.com/models/google/universal-sentence-encoder/frameworks/TensorFlow2/variations/universal-sentence-encoder/versions/2\")\n",
    "embed_samples = embed([sample_sentence,\n",
    "                      \"When you can the universal sentence encoder on a sentence, it turns it into numbers.\"])\n",
    "print(embed_samples[0][:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "eb32f6f1-68fc-4807-b1c3-4137739373ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([512])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_samples[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "018f4a3b-afa4-4986-a7bb-2d513cb961d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Keras layer using USE pretrained layer from tensorflow hub\n",
    "sentence_encoder_layer = hub.KerasLayer(\"https://www.kaggle.com/models/google/universal-sentence-encoder/frameworks/TensorFlow2/variations/universal-sentence-encoder/versions/2\",\n",
    "                                        input_shape=[],\n",
    "                                        dtype=tf.string,\n",
    "                                        trainable=False,\n",
    "                                        name = \"USE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "072886e6-db98-4151-b303-1283d8cca486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6_USE\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " USE (KerasLayer)            (None, 512)               256797824 \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 64)                32832     \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 256830721 (979.73 MB)\n",
      "Trainable params: 32897 (128.50 KB)\n",
      "Non-trainable params: 256797824 (979.61 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create model using the Sequential API\n",
    "model_6 = tf.keras.Sequential([\n",
    "    sentence_encoder_layer,\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "], name=\"model_6_USE\")\n",
    "\n",
    "# Compile the model\n",
    "model_6.compile(loss=\"binary_crossentropy\",\n",
    "               optimizer=tf.keras.optimizers.Adam(),\n",
    "               metrics=['accuracy'])\n",
    "\n",
    "model_6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6981f839-a3de-4f43-9d9a-ad50fe830faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/tf_hub_sentence_encoder/20240112-003959\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 5s 11ms/step - loss: 0.5037 - accuracy: 0.7802 - val_loss: 0.4486 - val_accuracy: 0.7966\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.4150 - accuracy: 0.8137 - val_loss: 0.4376 - val_accuracy: 0.8084\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.4005 - accuracy: 0.8216 - val_loss: 0.4334 - val_accuracy: 0.8136\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 0.3936 - accuracy: 0.8250 - val_loss: 0.4286 - val_accuracy: 0.8097\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.3876 - accuracy: 0.8282 - val_loss: 0.4299 - val_accuracy: 0.8150\n"
     ]
    }
   ],
   "source": [
    "# Train a classifier on top of USE pretrained embeddings\n",
    "model_6_history = model_6.fit(train_sentences,\n",
    "                             train_labels,\n",
    "                             validation_data=(val_sentences, val_labels),\n",
    "                             epochs=5,\n",
    "                             callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
    "                                                                   \"tf_hub_sentence_encoder\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "848eb327-dfb4-48bb-ae7b-14703cee11a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 7ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.15224092],\n",
       "       [0.7450482 ],\n",
       "       [0.98752743],\n",
       "       [0.20383276],\n",
       "       [0.7129781 ],\n",
       "       [0.6740718 ],\n",
       "       [0.9796668 ],\n",
       "       [0.97549736],\n",
       "       [0.92403775],\n",
       "       [0.09168851]], dtype=float32)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions with USE TF Hub Model\n",
    "model_6_pred_probs = model_6.predict(val_sentences)\n",
    "model_6_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1b1a50ba-c452-4f5e-8f64-f72bf9617a2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert predictions probabilities to labels\n",
    "model_6_preds = tf.squeeze(tf.round(model_6_pred_probs))\n",
    "model_6_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a3fbb59e-2a7b-4687-83cc-153dece82aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 81.49606299212599,\n",
       " 'precision': 0.8172549323109193,\n",
       " 'recall': 0.8149606299212598,\n",
       " 'f1-score': 0.8134357776936025}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate model 6 performace metris\n",
    "model_6_results = calculate_results(y_true=val_labels,\n",
    "                                   y_pred=model_6_preds)\n",
    "model_6_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3188cf-b985-4f3d-b7c6-67bd3e028f64",
   "metadata": {},
   "source": [
    "## Model 7: TF Hub Pretrained USE but with 10% of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "278ce582-2d65-4abc-94ea-4ab94be93381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Making data splits like this below leads to data leakage (model 7 trained on 10% data, outperforms model 6 trained on 100% data)\n",
    "## DO NOT MAKE DATA SPLITS WHICH LEAK DATA FROM VALIDATION/TEST SETS INTO TRAINING SET \n",
    "# Create subsets of 10% of training data\n",
    "# train_10_percent = train_df_shuffled[['text', 'target']].sample(frac=0.1, random_state=42)\n",
    "# Train_10_percent.head(), len(train_10_percent)\n",
    "# train_sentences_10_percent = train_10_percent['text'].to_list()\n",
    "# train_labels_10_percent = train_10_percent['target'].to_list()\n",
    "# len(train_sentences_10_percent), len(train_labels_10_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "7f73c8a2-d7ac-493c-b2f4-168abb748dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a better dataset split (no data leakage)\n",
    "train_10_percent_split = int(0.1 * len(train_sentences))\n",
    "train_sentences_10_percent = train_sentences[:train_10_percent_split]\n",
    "train_labels_10_percent = train_labels[:train_10_percent_split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "414dbdac-0914-4066-9d8c-11bea9c111b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    406\n",
       "1    279\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of each label in the updated training subset\n",
    "pd.Series(np.array(train_labels_10_percent)).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c83ffb-e04d-47f2-a7cd-46ac83bb32a1",
   "metadata": {},
   "source": [
    "> To recreate a model the same as a previous model you've created you can use the `tf.keras.models.clone_model()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "44183fec-f40e-4693-a2e8-2e5f83d8586e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7_USE\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " USE (KerasLayer)            (None, 512)               256797824 \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 64)                32832     \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 256830721 (979.73 MB)\n",
      "Trainable params: 32897 (128.50 KB)\n",
      "Non-trainable params: 256797824 (979.61 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Let's build a model the same as model_6\n",
    "# model_7 = tf.keras.models.clone_model(model_6)\n",
    "model_7 = tf.keras.Sequential([\n",
    "    sentence_encoder_layer,\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "], name=\"model_7_USE\")\n",
    "\n",
    "# Compile the model\n",
    "model_7.compile(loss='binary_crossentropy',\n",
    "               optimizer=tf.keras.optimizers.Adam(),\n",
    "               metrics=['accuracy'])\n",
    "\n",
    "model_7.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "e429d69f-44cf-4f2f-aaa1-eaf64094e817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/tf_hub_sentence_encoder_10_percent_correct_split/20240112-013234\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 2s 40ms/step - loss: 0.6759 - accuracy: 0.6555 - val_loss: 0.6537 - val_accuracy: 0.7323\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 0s 16ms/step - loss: 0.6102 - accuracy: 0.8044 - val_loss: 0.5994 - val_accuracy: 0.7533\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 0s 16ms/step - loss: 0.5351 - accuracy: 0.8073 - val_loss: 0.5426 - val_accuracy: 0.7717\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 0s 16ms/step - loss: 0.4715 - accuracy: 0.8190 - val_loss: 0.5091 - val_accuracy: 0.7703\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.4273 - accuracy: 0.8321 - val_loss: 0.4913 - val_accuracy: 0.7795\n"
     ]
    }
   ],
   "source": [
    "# Fit the model to the 10% training data \n",
    "model_7_history = model_7.fit(train_sentences_10_percent,\n",
    "                             train_labels_10_percent,\n",
    "                             epochs=5,\n",
    "                             validation_data=(val_sentences,val_labels),\n",
    "                             callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
    "                                                                   \"tf_hub_sentence_encoder_10_percent_correct_split\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "1797537d-ce0c-4fd8-805a-b23079b24b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 6ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.20283106],\n",
       "       [0.5698388 ],\n",
       "       [0.93173325],\n",
       "       [0.3712831 ],\n",
       "       [0.5343784 ],\n",
       "       [0.6959632 ],\n",
       "       [0.88990384],\n",
       "       [0.8373216 ],\n",
       "       [0.85186166],\n",
       "       [0.15911609]], dtype=float32)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictionswith the model trained on 10% of the data\n",
    "model_7_pred_probs = model_7.predict(val_sentences)\n",
    "model_7_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "0f99c1fb-dd12-417d-87d3-c1c9b68adc16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn pred probs into labels\n",
    "model_7_preds = tf.squeeze(tf.round(model_7_pred_probs))\n",
    "model_7_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "470e66c4-e3f2-4dbf-a870-310fbe9bc121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 77.95275590551181,\n",
       " 'precision': 0.7808713829501961,\n",
       " 'recall': 0.7795275590551181,\n",
       " 'f1-score': 0.7777699173240801}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the model 7 predictions\n",
    "model_7_results = calculate_results(y_true=val_labels,\n",
    "                                    y_pred=model_7_preds)\n",
    "model_7_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be4bf33-82b3-471c-b5a4-990a31ebaf48",
   "metadata": {},
   "source": [
    "## Comparing the performace of each of our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "5671c733-4cbb-4bc4-8ceb-6e5e689257ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0_baseline</th>\n",
       "      <td>79.265092</td>\n",
       "      <td>0.811139</td>\n",
       "      <td>0.792651</td>\n",
       "      <td>0.786219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_simple_dense</th>\n",
       "      <td>78.871391</td>\n",
       "      <td>0.794369</td>\n",
       "      <td>0.788714</td>\n",
       "      <td>0.785521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2_LSTM</th>\n",
       "      <td>76.115486</td>\n",
       "      <td>0.762766</td>\n",
       "      <td>0.761155</td>\n",
       "      <td>0.758852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3_GRU</th>\n",
       "      <td>76.902887</td>\n",
       "      <td>0.768765</td>\n",
       "      <td>0.769029</td>\n",
       "      <td>0.768248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4_BiDirectional</th>\n",
       "      <td>77.034121</td>\n",
       "      <td>0.772634</td>\n",
       "      <td>0.770341</td>\n",
       "      <td>0.767924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5_Conv1D</th>\n",
       "      <td>78.871391</td>\n",
       "      <td>0.793912</td>\n",
       "      <td>0.788714</td>\n",
       "      <td>0.785669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6_tf_hub_use_encoder</th>\n",
       "      <td>81.496063</td>\n",
       "      <td>0.817255</td>\n",
       "      <td>0.814961</td>\n",
       "      <td>0.813436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7_tf_hub_use_encoder_10_percent</th>\n",
       "      <td>77.952756</td>\n",
       "      <td>0.780871</td>\n",
       "      <td>0.779528</td>\n",
       "      <td>0.777770</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  accuracy  precision    recall  f1-score\n",
       "0_baseline                       79.265092   0.811139  0.792651  0.786219\n",
       "1_simple_dense                   78.871391   0.794369  0.788714  0.785521\n",
       "2_LSTM                           76.115486   0.762766  0.761155  0.758852\n",
       "3_GRU                            76.902887   0.768765  0.769029  0.768248\n",
       "4_BiDirectional                  77.034121   0.772634  0.770341  0.767924\n",
       "5_Conv1D                         78.871391   0.793912  0.788714  0.785669\n",
       "6_tf_hub_use_encoder             81.496063   0.817255  0.814961  0.813436\n",
       "7_tf_hub_use_encoder_10_percent  77.952756   0.780871  0.779528  0.777770"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine model results into a DataFrame\n",
    "all_model_results = pd.DataFrame({\"0_baseline\": baseline_results,\n",
    "                                 \"1_simple_dense\": model_1_results,\n",
    "                                 \"2_LSTM\": model_2_results,\n",
    "                                 \"3_GRU\": model_3_results,\n",
    "                                 \"4_BiDirectional\": model_4_results,\n",
    "                                 \"5_Conv1D\": model_5_results,\n",
    "                                 \"6_tf_hub_use_encoder\": model_6_results,\n",
    "                                 \"7_tf_hub_use_encoder_10_percent\": model_7_results})\n",
    "all_model_results = all_model_results.transpose()\n",
    "all_model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "5b64210c-d43d-4536-9fba-df46c979c8ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0_baseline</th>\n",
       "      <td>0.792651</td>\n",
       "      <td>0.811139</td>\n",
       "      <td>0.792651</td>\n",
       "      <td>0.786219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_simple_dense</th>\n",
       "      <td>0.788714</td>\n",
       "      <td>0.794369</td>\n",
       "      <td>0.788714</td>\n",
       "      <td>0.785521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2_LSTM</th>\n",
       "      <td>0.761155</td>\n",
       "      <td>0.762766</td>\n",
       "      <td>0.761155</td>\n",
       "      <td>0.758852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3_GRU</th>\n",
       "      <td>0.769029</td>\n",
       "      <td>0.768765</td>\n",
       "      <td>0.769029</td>\n",
       "      <td>0.768248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4_BiDirectional</th>\n",
       "      <td>0.770341</td>\n",
       "      <td>0.772634</td>\n",
       "      <td>0.770341</td>\n",
       "      <td>0.767924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5_Conv1D</th>\n",
       "      <td>0.788714</td>\n",
       "      <td>0.793912</td>\n",
       "      <td>0.788714</td>\n",
       "      <td>0.785669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6_tf_hub_use_encoder</th>\n",
       "      <td>0.814961</td>\n",
       "      <td>0.817255</td>\n",
       "      <td>0.814961</td>\n",
       "      <td>0.813436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7_tf_hub_use_encoder_10_percent</th>\n",
       "      <td>0.779528</td>\n",
       "      <td>0.780871</td>\n",
       "      <td>0.779528</td>\n",
       "      <td>0.777770</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 accuracy  precision    recall  f1-score\n",
       "0_baseline                       0.792651   0.811139  0.792651  0.786219\n",
       "1_simple_dense                   0.788714   0.794369  0.788714  0.785521\n",
       "2_LSTM                           0.761155   0.762766  0.761155  0.758852\n",
       "3_GRU                            0.769029   0.768765  0.769029  0.768248\n",
       "4_BiDirectional                  0.770341   0.772634  0.770341  0.767924\n",
       "5_Conv1D                         0.788714   0.793912  0.788714  0.785669\n",
       "6_tf_hub_use_encoder             0.814961   0.817255  0.814961  0.813436\n",
       "7_tf_hub_use_encoder_10_percent  0.779528   0.780871  0.779528  0.777770"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reduce the accuracy to the same scale as other metrics\n",
    "all_model_results['accuracy'] = all_model_results['accuracy']/100\n",
    "all_model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "2418ccea-5496-497e-a34f-df95eedda1f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot and compare all of the model results\n",
    "all_model_results.plot(kind=\"bar\", figsize=(10,7)).legend(bbox_to_anchor=(1.0,1.0));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "ba75f6c5-31c0-4711-8048-1d2b71e8df36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sort model results by f1-score\n",
    "all_model_results.sort_values(\"f1-score\", ascending=False)['f1-score'].plot(kind=\"bar\", figsize=(10, 7));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f712a30-057a-4376-afad-2fb07fcac34d",
   "metadata": {},
   "source": [
    "## Saving and loading a trained model\n",
    "\n",
    "There are two formats to save a model to in TensorFlow:\n",
    "1. The HDF5 format\n",
    "2. The `SavedModel` format (this is the default when using TensorFlow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "dda21d57-da4f-41ec-9453-871846a926d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shrih\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Save TF Hub Sentence Encoder model to HDF5 format\n",
    "model_6.save(\"model_6.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "73a5e054-dfe5-4ea9-b7cf-3f765d8f3e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model with custom Hub Layer (required H5 format)\n",
    "Loaded_model_6 = tf.keras.models.load_model(\"model_6.h5\",\n",
    "                                           custom_objects={\"KerasLayer\": hub.KerasLayer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "d557173d-135c-4508-8954-17e8db295e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 2s 19ms/step - loss: 0.4299 - accuracy: 0.8150\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.42987561225891113, 0.8149606585502625]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how does our loaded model perform?\n",
    "Loaded_model_6.evaluate(val_sentences, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "6e266543-547b-4eaa-89c0-532d398510d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 81.49606299212599,\n",
       " 'precision': 0.8172549323109193,\n",
       " 'recall': 0.8149606299212598,\n",
       " 'f1-score': 0.8134357776936025}"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_6_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071cc9ec-d129-4376-91e4-68a4b5e0d5a1",
   "metadata": {},
   "source": [
    "Now let's save to the `SavedModel` format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "8a155f84-2657-4c23-9190-41330c8cf1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_6_SavedModel_format\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_6_SavedModel_format\\assets\n"
     ]
    }
   ],
   "source": [
    "# Save TF Hub Sentence Encoder model to SaveModel format (default)\n",
    "model_6.save(\"model_6_SavedModel_format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "545e4c92-8ade-4cc1-a5dd-932e427ac6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in a model from the SavedModel format\n",
    "loaded_model_6_SavedModel_format = tf.keras.models.load_model(\"model_6_SavedModel_format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "238fca6b-8bfc-4cf0-be30-4d014af6be34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 12ms/step - loss: 0.4299 - accuracy: 0.8150\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.42987561225891113, 0.8149606585502625]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate model in SavedModel format\n",
    "loaded_model_6_SavedModel_format.evaluate(val_sentences, val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f58a76e-abba-4615-a7f1-35756aa031ba",
   "metadata": {},
   "source": [
    "## Finding the most wrong examples\n",
    "* If our best model still isn't perfect, what examples is it getting wrong?\n",
    "* Which ones are the most wrong?\n",
    "* Are there some labels which are wrong? E.g. the model gets it right but the ground truth label doesn't reflect this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "656e6d1f-d39b-43d1-9735-8b91e17f71a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_6_pretrained = tf.keras.models.load_model(\"model_6_SavedModel_format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "8b4c9dc2-013d-4046-a338-16d0a336b943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 8ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions with the loaded model from GS\n",
    "model_6_pretrained_pred_probs = model_6_pretrained.predict(val_sentences)\n",
    "model_6_pretrained_preds = tf.squeeze(tf.round(model_6_pretrained_pred_probs))\n",
    "model_6_pretrained_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "bec5937c-6dfb-4062-b812-f067bf6e4831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>pred</th>\n",
       "      <th>pred_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DFR EP016 Monthly Meltdown - On Dnbheaven 2015...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.152241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FedEx no longer to transport bioterror germs i...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.745048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gunmen kill four in El Salvador bus attack: Su...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.987527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@camilacabello97 Internally and externally scr...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.203833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Radiation emergency #preparedness starts with ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.712978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>That's the ultimate road to destruction</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.101941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>@SetZorah dad why dont you claim me that mean ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.097843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>FedEx will no longer transport bioterror patho...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.855498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>Crack in the path where I wiped out this morni...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.699355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>I liked a @YouTube video from @dannyonpc http:...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.080777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>762 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  target  pred  \\\n",
       "0    DFR EP016 Monthly Meltdown - On Dnbheaven 2015...       0   0.0   \n",
       "1    FedEx no longer to transport bioterror germs i...       0   1.0   \n",
       "2    Gunmen kill four in El Salvador bus attack: Su...       1   1.0   \n",
       "3    @camilacabello97 Internally and externally scr...       1   0.0   \n",
       "4    Radiation emergency #preparedness starts with ...       1   1.0   \n",
       "..                                                 ...     ...   ...   \n",
       "757            That's the ultimate road to destruction       0   0.0   \n",
       "758  @SetZorah dad why dont you claim me that mean ...       0   0.0   \n",
       "759  FedEx will no longer transport bioterror patho...       0   1.0   \n",
       "760  Crack in the path where I wiped out this morni...       0   1.0   \n",
       "761  I liked a @YouTube video from @dannyonpc http:...       0   0.0   \n",
       "\n",
       "     pred_prob  \n",
       "0     0.152241  \n",
       "1     0.745048  \n",
       "2     0.987527  \n",
       "3     0.203833  \n",
       "4     0.712978  \n",
       "..         ...  \n",
       "757   0.101941  \n",
       "758   0.097843  \n",
       "759   0.855498  \n",
       "760   0.699355  \n",
       "761   0.080777  \n",
       "\n",
       "[762 rows x 4 columns]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create DataFrame with validation sentences, validation labels and best performing model predictions\n",
    "val_df = pd.DataFrame({\"text\": val_sentences,\n",
    "                      \"target\": val_labels,\n",
    "                      \"pred\": model_6_pretrained_preds,\n",
    "                      \"pred_prob\":  tf.squeeze(model_6_pretrained_pred_probs)})\n",
    "val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "7f2e0483-3fbe-410f-bad6-ff5f465cd90a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>pred</th>\n",
       "      <th>pred_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>? High Skies - Burning Buildings ? http://t.co...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.907337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>FedEx will no longer transport bioterror patho...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.855498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>@noah_anyname That's where the concentration c...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.845905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>@madonnamking RSPCA site multiple 7 story high...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.837428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>@SonofLiberty357 all illuminated by the bright...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.834396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>Ashes 2015: AustraliaÛªs collapse at Trent Br...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.809250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>[55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES W...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.800279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>@AshGhebranious civil rights continued in the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.794731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>The Sound of Arson</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.780323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>åÈMGN-AFRICAå¨ pin:263789F4 åÈ Correction: Ten...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.775859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  target  pred  \\\n",
       "31   ? High Skies - Burning Buildings ? http://t.co...       0   1.0   \n",
       "759  FedEx will no longer transport bioterror patho...       0   1.0   \n",
       "628  @noah_anyname That's where the concentration c...       0   1.0   \n",
       "49   @madonnamking RSPCA site multiple 7 story high...       0   1.0   \n",
       "393  @SonofLiberty357 all illuminated by the bright...       0   1.0   \n",
       "209  Ashes 2015: AustraliaÛªs collapse at Trent Br...       0   1.0   \n",
       "109  [55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES W...       0   1.0   \n",
       "251  @AshGhebranious civil rights continued in the ...       0   1.0   \n",
       "144                                 The Sound of Arson       0   1.0   \n",
       "698  åÈMGN-AFRICAå¨ pin:263789F4 åÈ Correction: Ten...       0   1.0   \n",
       "\n",
       "     pred_prob  \n",
       "31    0.907337  \n",
       "759   0.855498  \n",
       "628   0.845905  \n",
       "49    0.837428  \n",
       "393   0.834396  \n",
       "209   0.809250  \n",
       "109   0.800279  \n",
       "251   0.794731  \n",
       "144   0.780323  \n",
       "698   0.775859  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the wrong predictions and sort by prediction probabilites\n",
    "most_wrong = val_df[val_df[\"target\"] != val_df[\"pred\"]].sort_values(\"pred_prob\", ascending=False)\n",
    "most_wrong[:10] # These are false positives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7809b650-a90d-4c76-9aa8-042d05e4372f",
   "metadata": {},
   "source": [
    "Target labels\n",
    "\n",
    "`0` = not disaster\n",
    "\n",
    "`1` = disaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "a05ce3bc-bdc6-4621-ad10-eedc70100cc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>pred</th>\n",
       "      <th>pred_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>I get to smoke my shit in peace</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>Reddit Will Now QuarantineÛ_ http://t.co/pkUA...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>@SoonerMagic_ I mean I'm a fan but I don't nee...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Why are you deluged with low self-image? Take ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Ron &amp;amp; Fez - Dave's High School Crush https...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  target  pred  \\\n",
       "233                    I get to smoke my shit in peace       1   0.0   \n",
       "244  Reddit Will Now QuarantineÛ_ http://t.co/pkUA...       1   0.0   \n",
       "411  @SoonerMagic_ I mean I'm a fan but I don't nee...       1   0.0   \n",
       "38   Why are you deluged with low self-image? Take ...       1   0.0   \n",
       "23   Ron &amp; Fez - Dave's High School Crush https...       1   0.0   \n",
       "\n",
       "     pred_prob  \n",
       "233   0.044703  \n",
       "244   0.041284  \n",
       "411   0.035878  \n",
       "38    0.034617  \n",
       "23    0.032781  "
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_wrong.tail() # These are false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "83ca9455-4098-4534-8013-ab6402576308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: 0, pred: 1.0, Prob: 0.9073370695114136\n",
      "Text:\n",
      "? High Skies - Burning Buildings ? http://t.co/uVq41i3Kx2 #nowplaying\n",
      "\n",
      "-----\n",
      "\n",
      "Target: 0, pred: 1.0, Prob: 0.8554979562759399\n",
      "Text:\n",
      "FedEx will no longer transport bioterror pathogens in wake of anthrax lab mishaps http://t.co/lHpgxc4b8J\n",
      "\n",
      "-----\n",
      "\n",
      "Target: 0, pred: 1.0, Prob: 0.8459049463272095\n",
      "Text:\n",
      "@noah_anyname That's where the concentration camps and mass murder come in. \n",
      " \n",
      "EVERY. FUCKING. TIME.\n",
      "\n",
      "-----\n",
      "\n",
      "Target: 0, pred: 1.0, Prob: 0.8374277949333191\n",
      "Text:\n",
      "@madonnamking RSPCA site multiple 7 story high rise buildings next to low density character residential in an area that floods\n",
      "\n",
      "-----\n",
      "\n",
      "Target: 0, pred: 1.0, Prob: 0.8343958258628845\n",
      "Text:\n",
      "@SonofLiberty357 all illuminated by the brightly burning buildings all around the town!\n",
      "\n",
      "-----\n",
      "\n",
      "Target: 0, pred: 1.0, Prob: 0.8092496395111084\n",
      "Text:\n",
      "Ashes 2015: AustraliaÛªs collapse at Trent Bridge among worst in history: England bundled out Australia for 60 ... http://t.co/t5TrhjUAU0\n",
      "\n",
      "-----\n",
      "\n",
      "Target: 0, pred: 1.0, Prob: 0.8002787232398987\n",
      "Text:\n",
      "[55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES WITH MAGNE-TRACTION INSTRUCTIONS http://t.co/xEZBs3sq0y http://t.co/C2x0QoKGlY\n",
      "\n",
      "-----\n",
      "\n",
      "Target: 0, pred: 1.0, Prob: 0.7947311997413635\n",
      "Text:\n",
      "@AshGhebranious civil rights continued in the 60s. And what about trans-generational trauma? if anything we should listen to the Americans.\n",
      "\n",
      "-----\n",
      "\n",
      "Target: 0, pred: 1.0, Prob: 0.7803226709365845\n",
      "Text:\n",
      "The Sound of Arson\n",
      "\n",
      "-----\n",
      "\n",
      "Target: 0, pred: 1.0, Prob: 0.7758587598800659\n",
      "Text:\n",
      "åÈMGN-AFRICAå¨ pin:263789F4 åÈ Correction: Tent Collapse Story: Correction: Tent Collapse story åÈ http://t.co/fDJUYvZMrv @wizkidayo\n",
      "\n",
      "-----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checht the false positives (model predicted 1 when should've been 0)\n",
    "for row in most_wrong[:10].itertuples():\n",
    "    _, text, target, pred, pred_prob = row\n",
    "    print(f\"Target: {target}, pred: {pred}, Prob: {pred_prob}\")\n",
    "    print(f\"Text:\\n{text}\\n\")\n",
    "    print(\"-----\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "84a2279a-80a3-49ee-bf9a-afcf4eb9a9e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: 1, pred: 0.0, Prob: 0.05782010033726692\n",
      "Text:\n",
      "VICTORINOX SWISS ARMY DATE WOMEN'S RUBBER MOP WATCH 241487 http://t.co/yFy3nkkcoH http://t.co/KNEhVvOHVK\n",
      "\n",
      "-----\n",
      "\n",
      "Target: 1, pred: 0.0, Prob: 0.05666424334049225\n",
      "Text:\n",
      "going to redo my nails and watch behind the scenes of desolation of smaug ayyy\n",
      "\n",
      "-----\n",
      "\n",
      "Target: 1, pred: 0.0, Prob: 0.05605882406234741\n",
      "Text:\n",
      "You can never escape me. Bullets don't harm me. Nothing harms me. But I know pain. I know pain. Sometimes I share it. With someone like you.\n",
      "\n",
      "-----\n",
      "\n",
      "Target: 1, pred: 0.0, Prob: 0.053506698459386826\n",
      "Text:\n",
      "@willienelson We need help! Horses will die!Please RT &amp; sign petition!Take a stand &amp; be a voice for them! #gilbert23 https://t.co/e8dl1lNCVu\n",
      "\n",
      "-----\n",
      "\n",
      "Target: 1, pred: 0.0, Prob: 0.0520959347486496\n",
      "Text:\n",
      "Lucas Duda is Ghost Rider. Not the Nic Cage version but an actual 'engulfed in flames' badass. #Mets\n",
      "\n",
      "-----\n",
      "\n",
      "Target: 1, pred: 0.0, Prob: 0.044703155755996704\n",
      "Text:\n",
      "I get to smoke my shit in peace\n",
      "\n",
      "-----\n",
      "\n",
      "Target: 1, pred: 0.0, Prob: 0.04128392040729523\n",
      "Text:\n",
      "Reddit Will Now QuarantineÛ_ http://t.co/pkUAMXw6pm #onlinecommunities #reddit #amageddon #freespeech #Business http://t.co/PAWvNJ4sAP\n",
      "\n",
      "-----\n",
      "\n",
      "Target: 1, pred: 0.0, Prob: 0.035877808928489685\n",
      "Text:\n",
      "@SoonerMagic_ I mean I'm a fan but I don't need a girl sounding off like a damn siren\n",
      "\n",
      "-----\n",
      "\n",
      "Target: 1, pred: 0.0, Prob: 0.03461683914065361\n",
      "Text:\n",
      "Why are you deluged with low self-image? Take the quiz: http://t.co/XsPqdOrIqj http://t.co/CQYvFR4UCy\n",
      "\n",
      "-----\n",
      "\n",
      "Target: 1, pred: 0.0, Prob: 0.03278074041008949\n",
      "Text:\n",
      "Ron &amp; Fez - Dave's High School Crush https://t.co/aN3W16c8F6 via @YouTube\n",
      "\n",
      "-----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checht the false negatives (model predicted 0 when should've been 1)\n",
    "for row in most_wrong[-10:].itertuples():\n",
    "    _, text, target, pred, pred_prob = row\n",
    "    print(f\"Target: {target}, pred: {pred}, Prob: {pred_prob}\")\n",
    "    print(f\"Text:\\n{text}\\n\")\n",
    "    print(\"-----\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56c058f-2dd4-49cc-b822-9f3eb825424b",
   "metadata": {},
   "source": [
    "## Making predictions on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "3d39cf6e-1d32-491d-8067-905d8554459a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 287ms/step\n",
      "Pred: 0, Prob: 0.41903144121170044\n",
      "Text:\n",
      " Society will collapse by 2040 due to catastrophic food shortages says study http://t.co/2wWZBW5lId\n",
      "\n",
      "-----\n",
      "\n",
      "1/1 [==============================] - 0s 205ms/step\n",
      "Pred: 1, Prob: 0.5092760920524597\n",
      "Text:\n",
      " #360WiseNews : China's Stock Market Crash: Are There Gems In The Rubble? http://t.co/r0FLXJx5vX\n",
      "\n",
      "-----\n",
      "\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "Pred: 0, Prob: 0.06927476078271866\n",
      "Text:\n",
      " My new sounds: War Zone https://t.co/hNXRfqRk3P on #SoundCloud\n",
      "\n",
      "-----\n",
      "\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Pred: 0, Prob: 0.057990264147520065\n",
      "Text:\n",
      " People are bagging on Rousey's body? Shit I'd love to have a body like that. Those who are ridiculing her are probably dudes in skinny jeans\n",
      "\n",
      "-----\n",
      "\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "Pred: 0, Prob: 0.07219399511814117\n",
      "Text:\n",
      " @MikeParrActor if Ross is dead I shall never watch emmerdale again I'll be that heartbroken ??\n",
      "\n",
      "-----\n",
      "\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "Pred: 1, Prob: 0.803953230381012\n",
      "Text:\n",
      " #CecilTownship seeks emergency repairs to Southpointe Boulevard landslide: http://t.co/ZjJdt3so72\n",
      "\n",
      "-----\n",
      "\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "Pred: 0, Prob: 0.06602781265974045\n",
      "Text:\n",
      " I survived the tube strike! This is my victory smile ;D http://t.co/L3Y3x2Cats\n",
      "\n",
      "-----\n",
      "\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "Pred: 0, Prob: 0.10134489834308624\n",
      "Text:\n",
      " @itsTiimothy bhill bruh you can obliterate beez\n",
      "\n",
      "-----\n",
      "\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "Pred: 0, Prob: 0.33529365062713623\n",
      "Text:\n",
      " I crushed a 5.1 mi run with a pace of 13'0' with Nike+ SportWatch GPS. #nikeplus: http://t.co/lJiiuuaTRC\n",
      "\n",
      "-----\n",
      "\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "Pred: 0, Prob: 0.3459707200527191\n",
      "Text:\n",
      " ??Water fight??\n",
      "Penn park 6pm \n",
      "      BYOW\n",
      "(Bring Your Own Weapons)\n",
      "\n",
      "-----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Making predictions on the test dataset and visualizing them\n",
    "test_sentences = test_df['text'].to_list()\n",
    "test_samples = random.sample(test_sentences, 10)\n",
    "for test_sample in test_samples:\n",
    "    pred_prob = tf.squeeze(model_6.predict([test_sample])) # has to be list\n",
    "    pred = tf.round(pred_prob)\n",
    "    print(f\"Pred: {int(pred)}, Prob: {pred_prob}\")\n",
    "    print(f\"Text:\\n {test_sample}\\n\")\n",
    "    print(\"-----\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba05c17-24fa-4ab5-b0db-fd3be30e82f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
